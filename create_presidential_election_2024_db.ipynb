{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303969b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "class create_TW_presidentional_election_2024_DB:\n",
    "  def __init__(self, folder_path ='data'):\n",
    "    \"\"\"\n",
    "      Extracts county names from file names in a specified folder.\n",
    "\n",
    "      Args:\n",
    "          folder_path (str): The path to the folder. Defaults to 'data'.\n",
    "\n",
    "      Returns:\n",
    "          list: A list of extracted county names.\n",
    "      \"\"\"\n",
    "    try: \n",
    "      file_names_lst = os.listdir(folder_path)\n",
    "    # The regular expression pattern\n",
    "    # This pattern looks for:\n",
    "    # \\(  - an opening parenthesis (needs to be escaped with \\)\n",
    "    # (.+) - a capturing group that matches any character (.) one or more times (+)\n",
    "    # \\)  - a closing parenthesis\n",
    "    # when we use the full pattern \\((.+)\\), we are telling the computer: \"Find an opening parenthesis \\(, then capture whatever follows (.+), \n",
    "    # and stop when you find a closing parenthesis \\). The captured part is what you need.\"\n",
    "      pattern = r\"\\((.+)\\)\"\n",
    "      county_names_lst = []\n",
    "      for file_name in file_names_lst:\n",
    "        match = re.search(pattern, file_name)\n",
    "        if match:\n",
    "          extracted_name = match.group(1)\n",
    "        else:\n",
    "          print(f\"City name not found in the {file_name}.\")\n",
    "        county_names_lst.append(extracted_name)\n",
    "        \n",
    "      self.county_names = county_names_lst\n",
    "      print(f\">> county list saved to '_self_.county_names_lst'\\n\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "      print(f\"The folder '{folder_path}' does not exist.\\n\")\n",
    "      self.county_names = []\n",
    "\n",
    "  def tidy_county_df(self, county_name:str):\n",
    "    \"\"\"\n",
    "    Extracts and tidies election vote data for a specified county.\n",
    "\n",
    "    Args:\n",
    "        county_name (str): The name of the county for which to process data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned DataFrame in a long format, ready for analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Import and tidy up up each county's votes data\n",
    "    file_path = f'data\\總統-A05-4-候選人得票數一覽表-各投開票所({county_name}).xlsx'\n",
    "    city_df = pd.read_excel(file_path,skiprows=[0, 3, 4])\n",
    "\n",
    "    #  The headers of the raw data includes combined rows, modify the import method to streamline the data processing\n",
    "    city_df = city_df.iloc[:,:6]\n",
    "    candidates_names = city_df.iloc[0, 3:6].values.tolist()\n",
    "    city_df.columns = ['town', 'village', 'polling_place'] + candidates_names # rename the headers\n",
    "\n",
    "    # Foreward fill the town's name the villages inside the same town\n",
    "    city_df['town'] = city_df['town'].ffill()\n",
    "    city_df['town'] = city_df['town'].str.strip()\n",
    "\n",
    "    # Drop the rows that contain only the candidates' names and those contains the subtotal votes for each town\n",
    "    city_df = city_df.dropna()\n",
    "    city_df['polling_place'] = city_df['polling_place'].astype(int)\n",
    "\n",
    "    # --- Melt the DataFrame into a long data form ---\n",
    "    id_vars = ['town', 'village', 'polling_place']\n",
    "    melt_df = pd.melt(city_df, id_vars=id_vars, var_name='candidates_names',value_name='votes')\n",
    "    melt_df['county'] = county_name\n",
    "    return melt_df\n",
    "  \n",
    "  def aggregate_county_dataframe(self):    \n",
    "    # Aggregate all the counties into one Dataframe \n",
    "    agg_county_df = pd.DataFrame()\n",
    "    for county_name in self.county_names:\n",
    "      county_df = self.tidy_county_df(county_name)\n",
    "      agg_county_df = pd.concat([agg_county_df, county_df])\n",
    "    agg_county_df = agg_county_df.reset_index(drop=True) # drop the old indices\n",
    "    print(\">> Finished aggregating the county data and put it into the 'agg_county_df'.\")\n",
    "    self.agg_county_df = agg_county_df\n",
    "    print(f\">> aggregated dataframe saved to '_self_.agg_county_df'\\n\")\n",
    "    return agg_county_df\n",
    "  \n",
    "  def extract_columns_to_df (self, data, cols:list):\n",
    "    \"\"\"\n",
    "    Split the dfs into several databases based on the columns needed:.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The aggregated data from all the polling stations.\n",
    "        cols (list) : A list of the column names to extract from the aggregated dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned DataFrame in a long format, ready for analysis.\n",
    "    \"\"\"\n",
    "    new_df =  data.groupby(cols).count().reset_index()\n",
    "    new_df = new_df[cols].reset_index()\n",
    "    new_df['id'] = new_df.index + 1\n",
    "    print(f\"  Successifully extracted {cols} to a new DataFrame.\\n\") \n",
    "    return new_df\n",
    "  \n",
    "# ---- The main funciton of this class -----\n",
    "  def create_national_database(self, path='taiwan_presidential_election_2024.db'):\n",
    "    # Separate the candidate numbers from the names in column = candidates_names\n",
    "    numbers, candidates = [], []\n",
    "    agg_county_df = self.aggregate_county_dataframe()\n",
    "    col_to_split = agg_county_df['candidates_names']\n",
    "    for row in col_to_split:\n",
    "      number_pattern = r\"\\((.+)\\)\" \n",
    "      number_match = re.search(number_pattern, row)\n",
    "      number = number_match.group(1)\n",
    "      numbers.append(number)\n",
    "      name_pattern = row.split('\\n')\n",
    "      candidate = name_pattern[1] + '/' + name_pattern[2]\n",
    "      candidates.append(candidate)\n",
    "    print(\">> Finished tidy up the candidate information, including names and ids.\")\n",
    "\n",
    "    # Drop the candidate_names and join the newly split numbers and names\n",
    "    updated_national_df = agg_county_df.copy()\n",
    "    updated_national_df['candidate_number'] = numbers\n",
    "    updated_national_df['candidate_name'] = candidates\n",
    "    updated_national_df = updated_national_df.drop(columns=[\"candidates_names\"])\n",
    "    updated_national_df['votes'] = agg_county_df['votes'].values\n",
    "    print(\">> Updated the candidates' information to the aggregated dataframe.\")\n",
    "    \n",
    "    # Extract different pooling locations\n",
    "    print(\">> Extracting Dataframes...\\n\")\n",
    "    groupby_polling_places = self.extract_columns_to_df(updated_national_df,['town', 'village', 'polling_place', 'county'])\n",
    "    # Extract the candidates information\n",
    "    groupby_candidates = self.extract_columns_to_df(updated_national_df,['candidate_number','candidate_name'])\n",
    "    \n",
    "    # Join the two dfs\n",
    "    keys = ['county', 'town', 'village', 'polling_place']\n",
    "    national_votes_by_polling_places = pd.merge(\n",
    "                                                updated_national_df, \n",
    "                                                groupby_polling_places,\n",
    "                                                left_on=keys,\n",
    "                                                right_on=keys,\n",
    "                                                how = 'left') # updated_national_df on the left\n",
    "    national_votes_by_polling_places = national_votes_by_polling_places[['id','candidate_number','votes']]\n",
    "    national_votes_by_polling_places = national_votes_by_polling_places.rename(columns={'id':'polling_place_id','candidate_number':'candidate_id'})\n",
    "    print(\">> Finished joining the two Dataframes: national voting data & polling places.\\n\")\n",
    "    \n",
    "    # Create a SQLite database by sending query syntax to the app\n",
    "    absolute_path = os.path.abspath(path)\n",
    "    \n",
    "    # ADDED TIMEOUT: Gives other apps 20 seconds to finish before crashing\n",
    "    connection = sqlite3.connect(absolute_path, timeout=20.0)\n",
    "    connection = sqlite3.connect(absolute_path)\n",
    "    self.dfs = {\n",
    "            'polling_places': groupby_polling_places,\n",
    "            'candidates': groupby_candidates,\n",
    "            'votes': national_votes_by_polling_places\n",
    "              }\n",
    "    \n",
    "    print(f\">> Dataframes saved to '_self_.dfs'. Database at: {absolute_path}\")\n",
    "    \n",
    "    try: # Added try block to ensure closure\n",
    "      self.path = absolute_path \n",
    "      connection.execute(\"PRAGMA journal_mode=WAL;\") # ENABLE WAL MODE: Crucial for concurrency (reading while writing)\n",
    "      connection.execute(\"BEGIN IMMEDIATE;\") # START AN IMMEDIATE TRANSACTION: Locks the write-path early to prevent \"No such table\" errors\n",
    "      \n",
    "      groupby_polling_places.to_sql(\"polling_places\", con=connection,if_exists='replace', index=False)\n",
    "      groupby_candidates.to_sql(\"candidates\", con=connection,if_exists='replace', index=False)\n",
    "      national_votes_by_polling_places.to_sql(\"votes\", con=connection,if_exists='replace', index=False)\n",
    "      connection.commit() # commit the changes to make the new tables permanent\n",
    "      print(\">> Successfully imported tables: polling_places, candidates, and votes.\\n\")\n",
    "      \n",
    "      ### SQL syntax \n",
    "      cur = connection.cursor()\n",
    "      cur.execute(\"BEGIN IMMEDIATE;\")\n",
    "      cur.execute(\"DROP VIEW IF EXISTS votes_by_village;\")\n",
    "      create_view_sql = \"\"\"\n",
    "      CREATE VIEW votes_by_village AS \n",
    "      SELECT \n",
    "        polling_places.county,\n",
    "        polling_places.town, \n",
    "        polling_places.village,\n",
    "        candidates.candidate_number AS number,\n",
    "        SUM(votes.\"votes\") AS sum_votes\n",
    "        \n",
    "      FROM votes\n",
    "      LEFT JOIN polling_places\n",
    "        ON votes.polling_place_id = polling_places.id\n",
    "      LEFT JOIN candidates\n",
    "        ON votes.candidate_id = candidates.id\n",
    "        \n",
    "      GROUP BY \n",
    "        polling_places.county,\n",
    "        polling_places.town, \n",
    "        polling_places.village,\n",
    "        candidates.candidate_number;\n",
    "      \"\"\"\n",
    "      cur.execute(create_view_sql)\n",
    "      connection.commit()\n",
    "      print(\">> Successfully created view: votes_by_village.\\n\")\n",
    "      \n",
    "      # Verification: Check if the view actually returns rows\n",
    "      cur.execute(\"SELECT * FROM votes_by_village LIMIT 5;\")\n",
    "      sample_rows = cur.fetchall()\n",
    "\n",
    "      if sample_rows:\n",
    "          print(f\">> View Verified! Sample data: {sample_rows[0]}\")\n",
    "      else:\n",
    "          print(\"!! View created, but it appears to be empty. Check join keys.\")\n",
    "      \n",
    "    except Exception as e: # Catch errors to see exactly why it failed\n",
    "      # If anything fails, try to roll back to keep the DB stable\n",
    "      try:\n",
    "          connection.rollback()\n",
    "      except:\n",
    "          pass\n",
    "      print(f\"!! An error occurred: {e}\")\n",
    "      raise\n",
    "  \n",
    "    finally: #This ensures the connection closes even if the code crashes\n",
    "      connection.close()\n",
    "      print(\">> Database connection closed.\")\n",
    "  # Filtering function to select a certain county, town, and village.\n",
    "\n",
    "  def create_cosine_df(self):\n",
    "    # Load the previously created view from sql\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM votes_by_village; \n",
    "    \"\"\"\n",
    "    connection = sqlite3.connect(self.path)\n",
    "    votes_by_village = pd.read_sql(query,con=connection)\n",
    "    connection.close()\n",
    "\n",
    "    # Calculate the total polling percentage \n",
    "    total_votes = votes_by_village['sum_votes'].sum()\n",
    "    country_percentage = votes_by_village.groupby('number')['sum_votes'].sum()/total_votes\n",
    "    vector_a = country_percentage.values # translate the series to a one-dimensional ndarray\n",
    "\n",
    "    # Calculate the poling percentage by different municiapal combinations that include: county, town, and village\n",
    "    grouping_vars = ['county', 'town','village']\n",
    "    village_total_votes= votes_by_village.groupby(grouping_vars)['sum_votes'].sum()\n",
    "    add_village_total_votes = pd.merge(\n",
    "      votes_by_village, \n",
    "      village_total_votes, \n",
    "      left_on=grouping_vars,\n",
    "      right_on=grouping_vars,\n",
    "      how='left')\n",
    "\n",
    "    votes_by_candidates = 'sum_votes_x'\n",
    "    total_votes_per_village = 'sum_votes_y'\n",
    "    add_village_total_votes['village_percentage'] = add_village_total_votes[votes_by_candidates]/add_village_total_votes[total_votes_per_village]\n",
    "\n",
    "\n",
    "    # Transpose the Dataframe from long format to wide format so that every municipal combination will has a column for each candidate's votes in total polling precentage\n",
    "    pivot_df = add_village_total_votes.pivot(\n",
    "                                            index=grouping_vars,\n",
    "                                            columns='number',\n",
    "                                            values='village_percentage',\n",
    "                                            ).reset_index()\n",
    "\n",
    "\n",
    "    # Calculate the 'Cosine Similarity' for each municipal combinations\n",
    "    cosine_similarities = []\n",
    "    length_vector_a = pow((vector_a**2).sum(), 0.5)\n",
    "\n",
    "    cols_dict = {\n",
    "    \"candidate_pair1\": \"1\",\n",
    "    \"candidate_pair2\": \"2\",\n",
    "    \"candidate_pair3\": \"3\",\n",
    "    }\n",
    "\n",
    "    for row in pivot_df.iterrows():\n",
    "      data_series = row[1]\n",
    "      vector_bi = np.array(\n",
    "                          [data_series.loc[cols_dict[\"candidate_pair1\"]], \n",
    "                          data_series.loc[cols_dict[\"candidate_pair2\"]],\n",
    "                          data_series.loc[cols_dict[\"candidate_pair3\"]]])\n",
    "      vector_a_dot_vector_bi = np.dot(vector_a, vector_bi)\n",
    "      length_vector_bi = pow((vector_bi**2).sum(), 0.5)\n",
    "      cosine_similarity = vector_a_dot_vector_bi/(length_vector_a * length_vector_bi)\n",
    "      cosine_similarities.append(cosine_similarity)\n",
    "\n",
    "    # Cosine Similarity DataFrame\n",
    "    cosine_similarity_df = pivot_df.copy()\n",
    "    cosine_similarity_df['cosine_similarity'] = cosine_similarities\n",
    "    \n",
    "    cosine_similarity_df = cosine_similarity_df.sort_values(\n",
    "                                                            ['cosine_similarity','county','town','village'],\n",
    "                                                            ascending=[False, True, True, True]\n",
    "                                                            ).reset_index(drop=True) # removed the previously set indices\n",
    "    \n",
    "    cosine_similarity_df.reset_index() # create the new index after value sorting\n",
    "    cosine_similarity_df['similarity_rank'] = cosine_similarity_df.index + 1\n",
    "    cosine_similarity_df = cosine_similarity_df.rename(columns=cols_dict)\n",
    "    return vector_a, cosine_similarity_df\n",
    "\n",
    "\n",
    "  def filter_county_town_village(self, df, county_name:str, town_name:str, village_name:str):\n",
    "    county_condition =  df[\"county\"] == county_name\n",
    "    town_condition =  df[\"town\"] == town_name\n",
    "    village_condition =  df[\"village\"] == village_name\n",
    "    return  df[county_condition & town_condition & village_condition]\n",
    "  \n",
    "  def launch_radio_filter_UI(self):\n",
    "    country_percentage, gradio_df = self.create_cosine_df()\n",
    "    ko_wu, lai_hsiao, hou_chao = country_percentage\n",
    "\n",
    "    interfacr = gr.Interface(\n",
    "                            fn= self.filter_county_town_village,\n",
    "                            inputs=[\n",
    "                                    gr.Dataframe(gradio_df),\n",
    "                                    \"text\",\n",
    "                                    \"text\",\n",
    "                                    \"text\"\n",
    "                                    ],\n",
    "                            outputs= \"dataframe\",\n",
    "                            title=\"找出章魚里\",\n",
    "                            description=f\"輸入欲篩選的縣市、鄉鎮區與村鄰里: (柯吳配，賴蕭配，侯趙配) = ({ko_wu:.6f}, {lai_hsiao:.6f}, {hou_chao:.6f})\",  \n",
    "                            )\n",
    "    interfacr.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a494933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> county list saved to '_self_.county_names_lst'\n",
      "\n",
      ">> Finished aggregating the county data and put it into the 'agg_county_df'.\n",
      ">> aggregated dataframe saved to '_self_.agg_county_df'\n",
      "\n",
      ">> Finished tidy up the candidate information, including names and ids.\n",
      ">> Updated the candidates' information to the aggregated dataframe.\n",
      ">> Extracting Dataframes...\n",
      "\n",
      "  Successifully extracted ['town', 'village', 'polling_place', 'county'] to a new DataFrame.\n",
      "\n",
      "  Successifully extracted ['candidate_number', 'candidate_name'] to a new DataFrame.\n",
      "\n",
      ">> Finished joining the two Dataframes: national voting data & polling places.\n",
      "\n",
      ">> Dataframes saved to '_self_.dfs'. Database at: g:\\My Drive\\{Research} Projects\\2025_7 data analytic projects\\4_taiwan_presidential_election_2024\\taiwan_presidential_election_2024.db\n",
      ">> Successfully imported tables: polling_places, candidates, and votes.\n",
      "\n",
      ">> Successfully created view: votes_by_village.\n",
      "\n",
      ">> View Verified! Sample data: ('南投縣', '中寮鄉', '中寮村', '1', 81)\n",
      ">> Database connection closed.\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Functions Call\n",
    "\n",
    "## Temporarily filter the specific UserWarning from openpyxl\n",
    "warnings.filterwarnings(\n",
    "                        \"ignore\", \n",
    "                        message=\"Workbook contains no default style, apply openpyxl's default\", \n",
    "                        category=UserWarning\n",
    "                      )\n",
    "\n",
    "## Data cleaning \n",
    "election_db = create_TW_presidentional_election_2024_DB()\n",
    "election_db.create_national_database()\n",
    "election_db.launch_radio_filter_UI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taiwan_presidential_election_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
